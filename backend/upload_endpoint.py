import os
import uuid
import json
import re
from datetime import datetime
from fastapi import APIRouter, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
import tempfile
from openai import OpenAI
from supabase_client import supabase, SUPABASE_BUCKET
from config import OPENAI_API_KEY

router = APIRouter()

# Pas de fonctions d'extraction pr√©con√ßues - on copie fid√®lement ChatGPT

def extract_cv_with_chatgpt(file_path: str, filename: str) -> dict:
    """Extrait les informations du CV en utilisant l'Assistant OpenAI"""
    file_id = None
    thread_id = None
    run_id = None
    try:
        client = OpenAI(api_key=OPENAI_API_KEY)
        ASSISTANT_ID = "asst_WUGIISQND2sf1PMXok9QZdUt"
        
        # 1. Uploader le fichier vers OpenAI
        print(f"üì§ Upload du fichier {filename} vers OpenAI...")
        with open(file_path, 'rb') as file:
            response = client.files.create(
                file=file,
                purpose="assistants"
            )
        file_id = response.id
        print(f"‚úÖ Fichier upload√© avec l'ID: {file_id}")
        
        # 2. Cr√©er un thread
        thread = client.beta.threads.create()
        thread_id = thread.id
        print(f"üßµ Thread cr√©√© avec l'ID: {thread_id}")
        
        # 3. Ajouter le message avec le fichier au thread
        message = client.beta.threads.messages.create(
            thread_id=thread_id,
            role="user",
            content="""Analyse ce CV de mani√®re exhaustive et d√©taill√©e.

IMPORTANT : 
- Extrais TOUTES les informations du CV sans rien oublier
- Ne laisse AUCUNE information de c√¥t√© (m√™me les d√©tails les plus petits)
- Copie exactement le texte du CV, lettre par lettre, virgule par virgule, point par point
- Donne-moi une analyse texte libre, sans format JSON
- Organise tes r√©ponses par sections naturelles (personnel, formation, exp√©riences, comp√©tences, etc.)
- Sois ultra-d√©taill√© et exhaustif""",
            attachments=[{"file_id": file_id, "tools": [{"type": "file_search"}]}]
        )
        print(f"üí¨ Message ajout√© au thread")
        
        # 4. Lancer l'assistant
        run = client.beta.threads.runs.create(
            thread_id=thread_id,
            assistant_id=ASSISTANT_ID
        )
        run_id = run.id
        print(f"üöÄ Assistant lanc√© avec l'ID: {run_id}")
        
        # 5. Attendre que l'assistant termine
        while True:
            run_status = client.beta.threads.runs.retrieve(
                thread_id=thread_id,
                run_id=run_id
            )
            print(f"üìä Statut: {run_status.status}")
            
            if run_status.status == "completed":
                break
            elif run_status.status == "failed":
                raise Exception(f"L'assistant a √©chou√©: {run_status.last_error}")
            elif run_status.status == "expired":
                raise Exception("L'assistant a expir√©")
            
            import time
            time.sleep(2)  # Attendre 2 secondes avant de v√©rifier √† nouveau
        
        # 6. R√©cup√©rer la r√©ponse
        messages = client.beta.threads.messages.list(thread_id=thread_id)
        assistant_message = messages.data[0]  # Le premier message est la r√©ponse de l'assistant
        
        if assistant_message.content and len(assistant_message.content) > 0:
            content = assistant_message.content[0].text.value.strip()
        else:
            raise Exception("Aucune r√©ponse re√ßue de l'assistant")
        
        # Nettoyer la r√©ponse
        if content.startswith("```json"):
            content = content[7:]
        if content.endswith("```"):
            content = content[:-3]
        content = content.strip()
        
        # Debug: Afficher le contenu brut re√ßu
        print("üìÑ Contenu brut re√ßu de l'assistant:")
        print("=" * 80)
        print(content)
        print("=" * 80)
        print(f"üìè Longueur du contenu: {len(content)} caract√®res")
        
        # Copier fid√®lement le contenu de ChatGPT sans structure pr√©con√ßue
        print("üîç Copie fid√®le du contenu de ChatGPT...")
        print("üìù Format: COPIE EXACTE")
        
        # Diviser le contenu en sections selon ce que ChatGPT propose
        sections = re.split(r'\n\s*(?:===|###|##|#|\*\*|__)\s*', content)
        
        # Cr√©er une structure dynamique bas√©e sur les sections de ChatGPT
        extracted_data = {
            "raw_content": content,
            "format": "exact_copy"
        }
        
        # Ajouter chaque section telle quelle
        for i, section in enumerate(sections):
            section = section.strip()
            if not section:
                continue
            
            # Utiliser le titre de la section comme cl√©
            lines = section.split('\n')
            if lines:
                # Prendre la premi√®re ligne comme titre de section
                section_title = lines[0].strip().lower().replace(' ', '_').replace(':', '').replace('-', '_')
                section_content = '\n'.join(lines[1:]) if len(lines) > 1 else section
                
                # Ajouter la section √† la structure
                extracted_data[section_title] = section_content
        
        # Le parsing est maintenant g√©r√© dans la section pr√©c√©dente
        pass
        
                # Debug: Afficher la structure des donn√©es extraites
        print("üîç Structure des donn√©es extraites:")
        print("=" * 80)
        print(json.dumps(extracted_data, indent=2, ensure_ascii=False))
        print("=" * 80)
        
        # Afficher un r√©sum√© d√©taill√©
        print("üìä R√âSUM√â D√âTAILL√â DE L'EXTRACTION:")
        print("-" * 50)
        if 'personal_info' in extracted_data:
            personal = extracted_data['personal_info']
            print(f"üë§ Informations personnelles:")
            print(f"   - Nom: {personal.get('name', 'Non trouv√©')}")
            print(f"   - Email: {personal.get('email', 'Non trouv√©')}")
            print(f"   - T√©l√©phone: {personal.get('phone', 'Non trouv√©')}")
        
        if 'experiences' in extracted_data:
            experiences = extracted_data['experiences']
            print(f"üíº Exp√©riences: {len(experiences)} trouv√©es")
            for i, exp in enumerate(experiences, 1):
                print(f"   {i}. {exp.get('title', 'Sans titre')} chez {exp.get('company', 'Entreprise inconnue')}")
        
        if 'education' in extracted_data:
            education = extracted_data['education']
            print(f"üéì Formation: {len(education)} trouv√©e(s)")
            for i, edu in enumerate(education, 1):
                print(f"   {i}. {edu.get('degree', 'Dipl√¥me inconnu')} - {edu.get('institution', '√âtablissement inconnu')}")
        
        if 'skills' in extracted_data:
            skills = extracted_data['skills']
            total_skills = sum(len(v) if isinstance(v, list) else 0 for v in skills.values())
            print(f"üõ†Ô∏è Comp√©tences: {total_skills} au total")
            for category, skill_list in skills.items():
                if isinstance(skill_list, list) and skill_list:
                    print(f"   - {category}: {len(skill_list)} comp√©tences")
        
        print("-" * 50)
        
        # Validation de la structure avec flexibilit√© maximale
        print("üîç Validation de la structure des donn√©es...")
        
        # Analyser la structure g√©n√©r√©e par ChatGPT
        print("üìã Structure g√©n√©r√©e par ChatGPT:")
        for key, value in extracted_data.items():
            if isinstance(value, list):
                print(f"  - {key}: {len(value)} √©l√©ments")
            elif isinstance(value, dict):
                print(f"  - {key}: {len(value)} champs")
            else:
                print(f"  - {key}: {type(value).__name__}")
        
        # Normaliser les structures communes si elles existent
        if 'skills' in extracted_data and isinstance(extracted_data['skills'], dict):
            # Normaliser les comp√©tences si c'est un objet
            skill_categories = ['technical', 'soft', 'languages', 'tools', 'methodologies', 'frameworks', 'databases', 'cloud']
            for category in skill_categories:
                if category not in extracted_data['skills']:
                    extracted_data['skills'][category] = []
        elif 'skills' in extracted_data and isinstance(extracted_data['skills'], list):
            # Si skills est une liste, la convertir en objet
            extracted_data['skills'] = {'technical': extracted_data['skills']}
        
        # Normaliser les exp√©riences si c'est une liste
        if 'experiences' in extracted_data and not isinstance(extracted_data['experiences'], list):
            extracted_data['experiences'] = [extracted_data['experiences']]
        
        # Normaliser l'√©ducation si c'est une liste
        if 'education' in extracted_data and not isinstance(extracted_data['education'], list):
            extracted_data['education'] = [extracted_data['education']]
        
        # Afficher un r√©sum√© de ce qui a √©t√© extrait
        print("üìä R√©sum√© de l'extraction:")
        for key, value in extracted_data.items():
            if isinstance(value, list):
                print(f"  - {key}: {len(value)} √©l√©ments")
            elif isinstance(value, dict):
                if key == 'skills':
                    total_skills = sum(len(v) if isinstance(v, list) else 0 for v in value.values())
                    print(f"  - {key}: {total_skills} comp√©tences au total")
                else:
                    print(f"  - {key}: {len(value)} champs")
            else:
                print(f"  - {key}: {type(value).__name__}")
        
        return extracted_data

    except Exception as e:
        print(f"Erreur lors de l'extraction avec l'assistant: {e}")
        raise
    finally:
        # Nettoyer : supprimer le fichier et le thread
        if file_id:
            try:
                client.files.delete(file_id)
                print(f"üóëÔ∏è Fichier OpenAI supprim√©: {file_id}")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur suppression fichier OpenAI: {e}")
        
        if thread_id:
            try:
                client.beta.threads.delete(thread_id)
                print(f"üóëÔ∏è Thread supprim√©: {thread_id}")
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur suppression thread: {e}")

@router.post("/upload")
async def upload_file(file: UploadFile = File(...)):
    """Endpoint pour uploader un fichier CV et extraire les donn√©es avec ChatGPT"""
    try:
        # Validation du fichier
        if not file.filename:
            raise HTTPException(status_code=400, detail="Nom de fichier manquant")
        
        # V√©rifier l'extension
        allowed_extensions = {'.pdf', '.docx', '.doc'}
        file_extension = os.path.splitext(file.filename.lower())[1]
        
        if file_extension not in allowed_extensions:
            raise HTTPException(
                status_code=400, 
                detail=f"Type de fichier non support√©. Types autoris√©s: {', '.join(allowed_extensions)}"
            )
        
        # V√©rifier la taille (max 10MB)
        if file.size and file.size > 10 * 1024 * 1024:
            raise HTTPException(status_code=400, detail="Fichier trop volumineux (max 10MB)")
        
        # G√©n√©rer un ID unique
        file_id = str(uuid.uuid4())
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"cv_{file_id}_{timestamp}{file_extension}"
        
        # Sauvegarder temporairement le fichier
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as temp_file:
            content = await file.read()
            temp_file.write(content)
            temp_file_path = temp_file.name
        
        try:
            print(f"üîç Extraction des donn√©es avec ChatGPT pour {filename}")
            
            # Extraire les donn√©es avec ChatGPT
            extracted_data = extract_cv_with_chatgpt(temp_file_path, filename)
            
            # Upload vers Supabase Storage
            supabase.storage.from_(SUPABASE_BUCKET).upload(
                path=filename,
                file=content,
                file_options={"content-type": file.content_type}
            )
            
            # Enregistrer dans la base de donn√©es
            file_record = {
                "filename": filename,
                "content_type": file.content_type,
                "storage_path": filename
            }
            
            file_result = supabase.table("uploaded_files").insert(file_record).execute()
            db_file_id = file_result.data[0]['id']
            
            data_record = {
                "file_id": db_file_id,
                "data": extracted_data
            }
            
            supabase.table("resume_structured_data").insert(data_record).execute()
            
            return JSONResponse(content={
                "file_id": db_file_id,  # Return the database ID instead of UUID
                "filename": filename,
                "extracted_data": extracted_data,
                "status": "success",
                "message": "CV t√©l√©charg√© et extrait avec succ√®s"
            })
            
        finally:
            # Nettoyer le fichier temporaire
            if os.path.exists(temp_file_path):
                os.unlink(temp_file_path)
                
    except Exception as e:
        print(f"Erreur lors de l'upload: {e}")
        raise HTTPException(status_code=500, detail=f"Erreur lors du traitement: {str(e)}")

@router.get("/upload_status/{file_id}")
async def get_upload_status(file_id: str):
    """R√©cup√®re le statut d'un upload"""
    try:
        return JSONResponse(content={
            "file_id": file_id,
            "status": "completed",
            "message": "Extraction termin√©e"
        })
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur: {str(e)}")

 